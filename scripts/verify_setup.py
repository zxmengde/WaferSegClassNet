#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒå’Œä»£ç éªŒè¯è„šæœ¬

éªŒè¯:
1. Python ç¯å¢ƒå’Œä¾èµ–
2. CUDA å¯ç”¨æ€§
3. æ¨¡å‹å‰å‘ä¼ æ’­
4. æ•°æ®åŠ è½½ï¼ˆå¦‚æœæ•°æ®å­˜åœ¨ï¼‰

Usage:
    python scripts/verify_setup.py
"""

import sys
from pathlib import Path

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


def check_python_version():
    """æ£€æŸ¥ Python ç‰ˆæœ¬"""
    print("=" * 60)
    print("1. Python ç‰ˆæœ¬æ£€æŸ¥")
    print("=" * 60)
    
    version = sys.version_info
    print(f"Python ç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("âŒ éœ€è¦ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    
    print("âœ… Python ç‰ˆæœ¬ç¬¦åˆè¦æ±‚")
    return True


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("\n" + "=" * 60)
    print("2. ä¾èµ–æ£€æŸ¥")
    print("=" * 60)
    
    dependencies = [
        ("torch", "PyTorch"),
        ("torchvision", "TorchVision"),
        ("numpy", "NumPy"),
        ("pandas", "Pandas"),
        ("sklearn", "Scikit-learn"),
        ("matplotlib", "Matplotlib"),
        ("seaborn", "Seaborn"),
        ("yaml", "PyYAML"),
        ("tqdm", "tqdm"),
        ("cv2", "OpenCV"),
    ]
    
    all_ok = True
    for module, name in dependencies:
        try:
            __import__(module)
            print(f"âœ… {name}")
        except ImportError:
            print(f"âŒ {name} æœªå®‰è£…")
            all_ok = False
    
    return all_ok


def check_cuda():
    """æ£€æŸ¥ CUDA"""
    print("\n" + "=" * 60)
    print("3. CUDA æ£€æŸ¥")
    print("=" * 60)
    
    import torch
    
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰ GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPU æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print("âœ… CUDA é…ç½®æ­£ç¡®")
        return True
    else:
        print("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        return True  # ä¸å¼ºåˆ¶è¦æ±‚ CUDA


def check_model():
    """æ£€æŸ¥æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("4. æ¨¡å‹æ£€æŸ¥")
    print("=" * 60)
    
    try:
        import torch
        from models.multitask import WaferMultiTaskModel
        
        # åˆ›å»ºæ¨¡å‹
        model = WaferMultiTaskModel(
            classification_classes=38,
            segmentation_classes=1,
            separation_enabled=False,
        )
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        
        x = torch.randn(2, 3, 224, 224).to(device)
        outputs = model(x)
        
        print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"åˆ†ç±»è¾“å‡ºå½¢çŠ¶: {outputs['cls_logits'].shape}")
        print(f"åˆ†å‰²è¾“å‡ºå½¢çŠ¶: {outputs['seg_mask'].shape}")
        
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_data():
    """æ£€æŸ¥æ•°æ®"""
    print("\n" + "=" * 60)
    print("5. æ•°æ®æ£€æŸ¥")
    print("=" * 60)
    
    data_root = Path("data/processed")
    
    if not data_root.exists():
        print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬:")
        print("  python scripts/prepare_mixedwm38.py --input data/raw/Wafer_Map_Datasets.npz --output data/processed")
        return True  # ä¸å¼ºåˆ¶è¦æ±‚æ•°æ®å­˜åœ¨
    
    images_dir = data_root / "Images"
    labels_dir = data_root / "Labels"
    masks_dir = data_root / "Masks"
    
    if not images_dir.exists():
        print(f"âš ï¸ å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
        return True
    
    image_files = list(images_dir.glob("*.npy"))
    print(f"å›¾åƒæ–‡ä»¶æ•°é‡: {len(image_files)}")
    
    if len(image_files) == 0:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return True
    
    # å°è¯•åŠ è½½æ•°æ®é›†
    try:
        from data.dataset import MixedWM38Dataset
        
        dataset = MixedWM38Dataset(
            data_root=str(data_root),
            split="train",
            debug=True,
            max_per_class=2,
        )
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        if len(dataset) > 0:
            sample = dataset[0]
            print(f"æ ·æœ¬å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
            print(f"æ ·æœ¬ mask å½¢çŠ¶: {sample['mask'].shape}")
            print(f"æ ·æœ¬æ ‡ç­¾ (38ç±»): {sample['label_38'].item()}")
            print("âœ… æ•°æ®åŠ è½½æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_config():
    """æ£€æŸ¥é…ç½®"""
    print("\n" + "=" * 60)
    print("6. é…ç½®æ£€æŸ¥")
    print("=" * 60)
    
    config_path = Path("configs/e0.yaml")
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    try:
        from config_schema import load_config, validate_config
        
        config = load_config(str(config_path))
        errors = validate_config(config)
        
        if errors:
            print(f"âŒ é…ç½®éªŒè¯å¤±è´¥:")
            for err in errors:
                print(f"  - {err}")
            return False
        
        print(f"å®éªŒåç§°: {config.name}")
        print(f"æ‰¹æ¬¡å¤§å°: {config.data.batch_size}")
        print(f"å­¦ä¹ ç‡: {config.training.learning_rate}")
        print(f"è®­ç»ƒè½®æ•°: {config.training.epochs}")
        print("âœ… é…ç½®æ–‡ä»¶æœ‰æ•ˆ")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("\n" + "=" * 60)
    print("MixedWM38 é¡¹ç›®ç¯å¢ƒéªŒè¯")
    print("=" * 60)
    
    results = []
    
    results.append(("Python ç‰ˆæœ¬", check_python_version()))
    results.append(("ä¾èµ–", check_dependencies()))
    results.append(("CUDA", check_cuda()))
    results.append(("æ¨¡å‹", check_model()))
    results.append(("æ•°æ®", check_data()))
    results.append(("é…ç½®", check_config()))
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("éªŒè¯æ€»ç»“")
    print("=" * 60)
    
    all_passed = True
    for name, passed in results:
        status = "âœ…" if passed else "âŒ"
        print(f"{status} {name}")
        if not passed:
            all_passed = False
    
    print("\n" + "-" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡æ•°æ®: python scripts/prepare_mixedwm38.py --input data/raw/Wafer_Map_Datasets.npz --output data/processed --debug")
        print("2. è¿è¡Œè®­ç»ƒ: python train.py --config configs/e0.yaml --debug")
    else:
        print("âš ï¸ éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºä¿®å¤é—®é¢˜ã€‚")
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
